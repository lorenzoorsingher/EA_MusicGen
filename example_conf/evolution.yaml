music_generator:
  model: "facebook/musicgen-small"
  input_type: "text" # input type for the music generator, can be either text, token_embeddings or embeddings
  output_dir: "generated_audio"
  name: "musicgen"

music_model: "musicgen"

evolution:
  exp_name: "default"
  output_dir: "generated_audio"

  generations: 10 # number of generations to run the evolution for

  max_seq_len: 5 # maximum number of tokens in the prompt when using mode token or embeddings
  duration: 5 # duration of the generated music in seconds

  device: "cpu"

  logger:
    wandb: True # whether to use wandb for logging
    project: "MusicEvo" # wandb project name

    wandb_token: "WANDB_TOKEN" # wandb token

    visualizations: False # whether to use visualizations

  LLM: 
    api_key: "API_KEY"
    temperature: 0.7
    model: "gpt-4o-mini"
    api_uri : "https://api.openai.com/v1/chat/completions" # needs to be an OpenAI API compatible endpoint

  fitness:
    mode: "user" # can either be user, music or dynamic
    target_user: 0 # static target user for mode user
    target_music: "" # path to the target music for mode music

  search:
    mode: "LLM evolve" # available modes are full LLM, LLM evolve, CMAES, PGPE, XNES, SNES, CEM
    
    # general search parameters
    population_size: 50 # size of the population
    
    sample: True # use sampling for all opearations (both selecting individual and applying operators)
    novel_prompts: 0.1 # fraction of poupulation to create ex-novo, range [0,1]
    elites : 0.1 # fraction of population to keep from the previous, range [0,1]
    
    # full LLM parameters
    
    # LLM evolve parameters
    tournament_size: 5 # size of the tournament for selection
    LLM_genetic_operators: 
    # genetic operators to use when using the LLM evolve mode 
    # NOTE: they are applied to the whole population one by one
    # you can create operators that apply multiple opearations at the same time by describing what you want the LLM to do
    # do not use anywhere the <propt> </prompt> tags, as they are used to extract the final output from the LLM
      - name: "cross over"
        description: "take the two prompts provided and cross them over by mixing components of both"
        input: 2 # number of parents
        output: 1 # number of children
        probability: 0.5 # the probability of applying the operator
      - name: "change genere"
        description: "take the prompt and change the genre of the music used"
        input: 1 # number of parents
        output: 1 # number of children
        probability: 0.5
      - name: "random mutation"
        input: 1 # number of parents
        output: 1 # number of children
        description: "take the prompt and mutate it, you can choose to mutate any of the words in the prompt"
        probability: 0.5
    
    # evotorch parameters
    evotorch: # additional parameters for the search algorithm when using evotorch's algorithms
      parameter1: "value1" 


  
